{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "In this notebook I write the final versions of the functions I am using in the simulation. They are created as if they were to be used in a package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from scipy.signal import gaussian, convolve\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy.optimize import minimize, fsolve\n",
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandwidth selectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scott's rule\n",
    "I decide to implement the robust rule. I think it is safer.\n",
    "\n",
    "$$\n",
    "h_{\\text{Scott}} = 1.06 A N ^ {-0.2}\n",
    "$$\n",
    "\n",
    "where $A = \\min\\{\\hat{\\sigma}, \\frac{R}{1.34}\\}$ is a robust measure of the dispersion in the observations. $R$ represents the inter-quartile range, defined as\n",
    "\n",
    "$$\n",
    "R = \\underbrace{X_{([0.75N])}}_{\\text{75% quantile}} - \\underbrace{X_{([0.25N])}}_{\\text{25% quantile}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bw_scott(x):\n",
    "    a = min(np.std(x), stats.iqr(x) / 1.34)\n",
    "    bw = 1.06 * a * len(x) ** (-0.2)\n",
    "    return bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silverman's rule\n",
    "\n",
    "Just as Scott's rule but the multiplying factor is 0.9 instead of 1.06\n",
    "\n",
    "$$\n",
    "h_{\\text{Silverman}} = 0.9 A N ^ {-0.2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bw_silverman(x):\n",
    "    a = min(np.std(x), stats.iqr(x) / 1.34)\n",
    "    bw = 0.9 * a * len(x) ** (-0.2)\n",
    "    return bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares Cross-Validation\n",
    "\n",
    "$h_{\\text{LSCV}}$ is defined as the value of $h$ that minimizes\n",
    "\n",
    "$$\n",
    "\\text{LSCV}(h) = \\int{[\\hat{f}(x; h)]^2dx} - \\frac{2}{N} \\sum_{i=1}^N{\\hat{f}_{-i}(X_i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_ise_loocv(h, x, x_min, x_max):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes the Integrated Squared Error (ISE) via Leave-One-Out Cross-Validation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy array\n",
    "        1 dimensional array of sample data from the variable for which a \n",
    "        density estimate is desired.\n",
    "    h : float\n",
    "        Bandwidth (standard deviation of each Gaussian component)\n",
    "    x_min : float\n",
    "        Lower limit for the domain of the variable\n",
    "    x_max : float\n",
    "        Upper limit for the domain of the variable\n",
    "  \n",
    "    Returns\n",
    "    -------\n",
    "    lscv_error : Float, estimation of the Least Squares Cross-Validation Error.   \n",
    "    \"\"\"\n",
    "    \n",
    "    x_len = len(x)\n",
    "    \n",
    "    dens = sm.nonparametric.KDEUnivariate(x)\n",
    "    dens.fit(kernel='gau', bw=h)\n",
    "    f_squared = lambda x : dens.evaluate(x) ** 2\n",
    "    \n",
    "    # Compute first term of LSCV(h)\n",
    "    f_sq_twice_area =  2 * quad(f_squared, x_min, x_max)[0]\n",
    "    \n",
    "    # Compute second term of LSCV(h)\n",
    "    f_loocv_sum = 0\n",
    "    for i in range(x_len):\n",
    "        dens1 = sm.nonparametric.KDEUnivariate(np.delete(x, i))\n",
    "        dens1.fit(kernel='gau', bw=h)\n",
    "        f_loocv_sum += dens.evaluate(x[i])\n",
    "    f_loocv_sum *= (2 / x_len)\n",
    "\n",
    "    # LSCV(h)\n",
    "    lscv_error = np.abs(f_sq_twice_area - f_loocv_sum)\n",
    "    \n",
    "    return lscv_error\n",
    "\n",
    "def bw_lscv(x):\n",
    "    \"\"\"\n",
    "    Computes Least Squares Cross-Validation bandwidth for a Gaussian KDE\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : 1-D numpy array\n",
    "        1 dimensional array of sample data from the variable for which a \n",
    "        density estimate is desired.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    h : float\n",
    "        Bandwidth estimated via Least Squares Cross-Validation\n",
    "    \"\"\"\n",
    "    \n",
    "    x_len = len(x)\n",
    "    x_std = np.std(x)\n",
    "    x_min = np.min(x) - 0.5 * x_std\n",
    "    x_max = np.max(x) + 0.5 * x_std   \n",
    "    \n",
    "    # Silverman's rule as initial value for h\n",
    "    s = min(x_std, stats.iqr(x) / 1.34)\n",
    "    h0 = 0.9 * s * x_len ** (-0.2)\n",
    "    \n",
    "    # h is constrained to be larger than 10**(-8)\n",
    "    constraint = ({'type':'ineq', 'fun':lambda x : x - 10 ** (-8)})\n",
    "    result = minimize(_get_ise_loocv, h0, args=(x, x_min, x_max), constraints=constraint)\n",
    "    h = result.x[0]\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sheather-Jones plug-in method\n",
    "\n",
    "$h_{\\text{SJ}}$ is the solution to the equation\n",
    "\n",
    "$$\n",
    "\\left[\\frac{R(\\kappa)}{\\mu_2(\\kappa)^2\\hat{S}(g(h))} \\right] ^ {1/5} n ^{-1/5} - h = 0\n",
    "$$\n",
    "\n",
    "For a description see notebook `03_more_bandwidth_selectors`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _phi6(x):\n",
    "    return (x ** 6 - 15 * x ** 4 + 45 * x ** 2 - 15) * stats.norm.pdf(x)\n",
    "\n",
    "def _phi4(x):\n",
    "    return (x ** 4 - 6 * x ** 2 + 3) * stats.norm.pdf(x)\n",
    "\n",
    "def aux_sum1(x, fun, den):\n",
    "    out = np.sum(np.sum(fun(x / den), 0))\n",
    "    return out\n",
    "\n",
    "def aux_sum2(x, fun, den):\n",
    "    out = 0\n",
    "    for i in range(len(x)):\n",
    "        out += np.sum(fun((x[i] - x) / den))\n",
    "\n",
    "def _sj_helper(h, s_a, t_b, x_len, x_len_mult, x_pairwise_diff):\n",
    "    \"\"\"\n",
    "    Equation 12 of Sheather and Jones [1]\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    .. [1] A reliable data-based bandwidth selection method for kernel\n",
    "        density estimation. Simon J. Sheather and Michael C. Jones.\n",
    "        Journal of the Royal Statistical Society, Series B. 1991\n",
    "    \"\"\"\n",
    "    \n",
    "    numerator = 0.375 * np.pi ** -0.5  \n",
    "    g_h = 1.357 * np.abs(s_a / t_b) ** (1 / 7) * h ** (5 / 7)\n",
    "    s_g = np.sum(np.sum(_phi4(x_pairwise_diff / g_h), 0))\n",
    "    s_g *= x_len_mult * g_h ** -5\n",
    "    \n",
    "    output = (numerator / np.abs(s_g * x_len)) ** 0.2 - h\n",
    "    \n",
    "    return output\n",
    "\n",
    "def bw_sj(x):\n",
    "    \"\"\"\n",
    "    Computes Sheather-Jones bandwidth for Gaussian KDE\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy array\n",
    "        1 dimensional array of sample data from the variable for which a \n",
    "        density estimate is desired.  \n",
    "    Returns\n",
    "    -------\n",
    "    h : float\n",
    "        Bandwidth estimated via Least Squares Cross-Validation\n",
    "    \"\"\"\n",
    "    \n",
    "    x_len = len(x)\n",
    "    x_std = np.std(x)\n",
    "    x_iqr = stats.iqr(x)\n",
    "    \n",
    "    a = 0.92 * x_iqr * x_len ** (-1 / 7)\n",
    "    b = 0.912 * x_iqr * x_len ** (-1 / 9) \n",
    "    \n",
    "    x_len_mult = 1 / (x_len * (x_len - 1))\n",
    "    x_matrix = np.tile(x, (x_len, 1))\n",
    "    x_pairwise_diff = x - x[:, None]\n",
    "    \n",
    "    if x_len <= 5000:\n",
    "        t_b = aux_sum1(x_pairwise_diff, phi6, b)\n",
    "        t_b *= - x_len_mult * b ** -7\n",
    "        \n",
    "        s_a = aux_sum1(x_pairwise_diff, phi4, a)\n",
    "        s_a *= x_len_mult * a ** -5\n",
    "    else:\n",
    "        t_b = aux_sum1(x, phi6, b)\n",
    "        t_b *= - x_len_mult * b ** -7\n",
    "        \n",
    "        s_a = aux_sum1(x, phi6, a)\n",
    "        s_a *= x_len_mult * a ** -5\n",
    "    \n",
    "    h0 = 0.9 * x_std * x_len ** (-0.2)\n",
    "    \n",
    "    result = fsolve(_sj_helper, h0, args=(s_a, t_b, x_len, x_len_mult, x_pairwise_diff))\n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Sheather-Jones plug-in method\n",
    "\n",
    "The Improved Sheather-Jones bandwidth is the *typically unique* solution to the following non-linear equation:\n",
    "\n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "  t = \\zeta\\gamma^{[l]}(t), & \\text{for large enough}\\ l\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "For a description see notebook `03_more_bandwidth_selectors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dct1d(x):\n",
    "    \"\"\"\n",
    "    Discrete Cosine Transform in 1 Dimension\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy array\n",
    "        1 dimensional array of values for which the \n",
    "        DCT is desired\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    output : DTC transformed values\n",
    "    \"\"\"\n",
    "\n",
    "    x_len = len(x)\n",
    "\n",
    "    even_increasing = np.arange(0, x_len, 2)\n",
    "    odd_decreasing = np.arange(x_len - 1, 0, -2)\n",
    "\n",
    "    x = np.concatenate((x[even_increasing], x[odd_decreasing]))\n",
    "    \n",
    "    w_1k = np.r_[1, (2 * np.exp(-(0 + 1j) * (np.arange(1, x_len)) * np.pi / (2 * x_len)))]\n",
    "    output = np.real(w_1k * fft(x))\n",
    "    \n",
    "    return output\n",
    "\n",
    "def _idct1d(x):\n",
    "    \"\"\"\n",
    "    Inverse Discrete Cosine Transform in 1 Dimension\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy array\n",
    "        1 dimensional array of values for which the \n",
    "        IDCT is desired\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    output : IDCT transformed values\n",
    "    \"\"\"\n",
    "\n",
    "    x_len = len(x)\n",
    "\n",
    "    w_2k = x * np.exp((0 + 1j) * np.arange(0, x_len) * np.pi / (2 * x_len))\n",
    "    x = np.real(ifft(w_2k))\n",
    "\n",
    "    output = np.zeros(x_len)\n",
    "    output[np.arange(0, x_len, 2, dtype=int)] = x[np.arange(0, x_len / 2, dtype=int)]\n",
    "    output[np.arange(1, x_len, 2, dtype=int)] = x[np.arange(x_len - 1, (x_len / 2) - 1, -1, dtype=int)]\n",
    "\n",
    "    return output\n",
    "\n",
    "def _fixed_point(t, N, k_sq, a_sq):\n",
    "    # This implements the function t-zeta*gamma^[l](t) in 3.23\n",
    "    # To avoid prevent powers from overflowing.\n",
    "    k_sq = np.asfarray(k_sq, dtype='float')\n",
    "    a_sq = np.asfarray(a_sq, dtype='float')\n",
    "\n",
    "    l = 7\n",
    "    f = 0.5 * np.pi ** (2.0 * l) * np.sum(k_sq ** l * a_sq * np.exp(-k_sq * np.pi ** 2.0 * t))\n",
    "\n",
    "    for j in reversed(range(2, l)):\n",
    "        c1  = (1 + 0.5**(j + 0.5)) / 3.0\n",
    "        c2  = np.product(np.arange(1., 2. * j + 1., 2., dtype = 'float')) / (np.pi / 2) ** 0.5\n",
    "        t_j = np.power((c1 * c2 / (N * f)), (2 / (3 + 2 * j)))\n",
    "        f   = 0.5 * np.pi ** (2. * j) * np.sum(k_sq ** j * a_sq * np.exp(-k_sq * np.pi ** 2. * t_j) )\n",
    "\n",
    "    out = np.abs(t - (2. * N * np.pi ** 0.5 * f) ** (-0.4))\n",
    "    return out\n",
    "\n",
    "def bw_isj(x):\n",
    "    \n",
    "    x_len = len(x)\n",
    "    x_min = np.min(x)\n",
    "    x_max = np.max(x)\n",
    "    x_range = x_max - x_min\n",
    "    x_std = np.std(x)\n",
    "    \n",
    "    grid_len = 256\n",
    "    grid_min = x_min - 0.5 * x_std\n",
    "    grid_max = x_max + 0.5 * x_std\n",
    "       \n",
    "    # Relative frequency per bin\n",
    "    f, edges = np.histogram(x, bins=grid_len, range=(grid_min, grid_max))\n",
    "    f = f / x_len\n",
    "\n",
    "    # Discrete cosine transform of the data\n",
    "    a_k = _dct1d(f)\n",
    "    \n",
    "    k_sq = np.arange(1, grid_len) ** 2\n",
    "    a_sq = a_k[range(1, grid_len)] ** 2\n",
    "    \n",
    "    t = fsolve(_fixed_point, 0.02, args=(x_len, k_sq, a_sq))\n",
    "    h = t[0] ** 0.5 * x_range\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental bandwidth\n",
    "\n",
    "This is just a personal guess on some experimentation performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bw_experimental(x):\n",
    "    return 0.5 * (bw_silverman(x) + bw_isj(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usable function\n",
    "\n",
    "This function is a generic to call any of the bandwidth selection methods. It includes a custom method that combines Silverman's rule with the improved Sheather-Jones, which is based on a personal interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_bw_methods = {\n",
    "    \"scott\": bw_scott,\n",
    "    \"silverman\": bw_silverman,\n",
    "    \"lscv\": bw_lscv,\n",
    "    \"sj\" : bw_sj,\n",
    "    \"isj\" : bw_isj,\n",
    "    \"experimental\" : bw_experimental\n",
    "}\n",
    "\n",
    "def _select_bw_method(x, method=\"isj\"):\n",
    "    method_lower = method.lower()\n",
    "\n",
    "    if method_lower not in _bw_methods.keys():\n",
    "        error_string = \"Unrecognized bandwidth method.\\n\"\n",
    "        error_string += f\"Input is: {method}.\\n\"\n",
    "        error_string += f\"Expected one of: {list(_bw_methods.keys())}.\"\n",
    "        raise ValueError(error_string)\n",
    "        \n",
    "    bw = _bw_methods[method_lower](x)\n",
    "    return bw\n",
    "\n",
    "def get_bw(x, bw):\n",
    "    if isinstance(bw, (int, float)):\n",
    "        if bw > 0:\n",
    "            return bw\n",
    "        else:\n",
    "            error_string = \"Numeric `bw` must be positive.\\n\"\n",
    "            error_string += f\"Input: {bw:.4f}.\"\n",
    "            raise ValueError(error_string)\n",
    "\n",
    "    elif isinstance(bw, str):\n",
    "        return _select_bw_method(x, bw)\n",
    "    else:\n",
    "        error_string = \"Unrecognized `bw` argument.\\n\"\n",
    "        error_string += f\"Input {bw} is of type {type(bw)}.\\n\"\n",
    "        error_string += f\"Expected a positive numeric or one of the following strings: {list(_bw_methods.keys())}.\" \n",
    "        raise ValueError(error_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "\n",
    "def _check_type(x):\n",
    "    \n",
    "    if not isinstance(x, (list, np.ndarray)):\n",
    "        error_str = f\"`x` is of the wrong type.\\n\"\n",
    "        error_str += f\"Can't produce a density estimator for {type(x)}.\\n\"\n",
    "        error_str += f\"Please input a numeric list or numpy array.\"\n",
    "        raise ValueError(error_str)\n",
    "    \n",
    "    # Will raise an error if `x` is not numeric\n",
    "    x = np.asfarray(x)\n",
    "    \n",
    "    if x.ndim != 1:\n",
    "        error_str = f\"Unsupported dimension number.\\n\"\n",
    "        error_str += f\"Density estimator only works with 1-dimensional data, \"\n",
    "        error_str += f\"not {x.ndim}.\"\n",
    "        raise ValueError(error_str)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def _len_warning(x):\n",
    "    if x < 50: \n",
    "        warn_str = f\"The estimation may be unstable for such a few data points.\\n\"\n",
    "        warn_str += f\"Try a histogram or dotplot instead.\"\n",
    "        warn(warn_str, Warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal estimators\n",
    "\n",
    "The first function, `kde_convolution`, performs the density estimation via the convolution of the sample empirical distribution and a Gaussian signal. It is the fastest apporach. However it cannot be used when the bandwidth is not constant.  \n",
    "For the latter case, we have `kde_adaptive`. This also estimates the density using the binning method (convolution is a faster way of getting the binned sum), but enables adaptivity. \n",
    "\n",
    "Both functions support boundary correction, but `kde_adaptive` is the one that suffers the highest time increment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kde_convolution(x, bw, grid_len, grid_min, grid_max, bound_correction):\n",
    "    \n",
    "    # Calculate relative frequencies per bin\n",
    "    f, edges = np.histogram(x, bins=grid_len, range=(grid_min, grid_max), density=True)  \n",
    "\n",
    "    # Bandwidth must consider the bin width\n",
    "    bin_width = (grid_max - grid_min) / (grid_len - 1)\n",
    "    bw /= bin_width\n",
    "    \n",
    "    # Instantiate kernel signal\n",
    "    kernel = gaussian(120, bw)\n",
    "    \n",
    "    if bound_correction:\n",
    "        npad = int(grid_len / 4)\n",
    "        f = np.concatenate([f[npad: 0: -1], f, f[grid_len : grid_len - npad : -1]])\n",
    "        pdf = convolve(f, kernel, mode=\"same\", method=\"direct\")[npad : npad + grid_len]\n",
    "        pdf = pdf / sum(kernel)\n",
    "    else:\n",
    "        pdf = convolve(f, kernel, mode=\"same\", method=\"direct\") / sum(kernel)\n",
    "    \n",
    "    grid = np.linspace(grid_min, grid_max, num=grid_len)\n",
    "    \n",
    "    return grid, pdf\n",
    "\n",
    "def kde_adaptive(x, bw, grid_len, grid_min, grid_max, bound_correction):\n",
    "\n",
    "    # Computations for bandwidth adjustment\n",
    "    pilot_grid, pilot_pdf = kde_convolution(x, bw, grid_len, grid_min, grid_max, bound_correction)\n",
    "    \n",
    "    # Step 2: Determine the modification factors\n",
    "    # a: Geometric mean of KDE evaluated at sample points\n",
    "    # EXTREMELY important to calculate geom_mean with interpolated points\n",
    "    # and `adj_factor` with `pilot_pdf`.\n",
    "    pdf_interp = np.interp(x, pilot_grid, pilot_pdf)\n",
    "    geom_mean = np.exp(np.mean(np.log(pdf_interp)))\n",
    "    \n",
    "    # b: Compute modification factors\n",
    "    # Power of c = 0.5\n",
    "    adj_factor = (geom_mean / pilot_pdf) ** 0.5\n",
    "    bw_adj = bw * adj_factor\n",
    "    \n",
    "    # Estimation of Gaussian KDE via binned method (convolution not possible)\n",
    "    grid_count, grid = np.histogram(x, bins=grid_len, range=(grid_min, grid_max))\n",
    "    grid = (grid[1:]  + grid[:-1]) / 2\n",
    "    \n",
    "    if bound_correction:\n",
    "        \n",
    "        x_pad_min = (2 * grid_min) - grid_max\n",
    "        x_pad_max = (2 * grid_max) - grid_min\n",
    "        grid_pad_len = 3 * grid_len\n",
    "        \n",
    "        grid = np.linspace(x_pad_min, x_pad_max, num=grid_pad_len)\n",
    "        grid = (grid[1:]  + grid[:-1]) / 2\n",
    "        \n",
    "        grid_count = np.concatenate([\n",
    "            grid_count[grid_pad_len: 0: -1], \n",
    "            grid_count, \n",
    "            grid_count[grid_len : grid_len - grid_pad_len : -1]]\n",
    "        )\n",
    "        \n",
    "        bw_adj = np.concatenate([\n",
    "            bw_adj[grid_pad_len: 0: -1], \n",
    "            bw_adj, \n",
    "            bw_adj[grid_len : grid_len - grid_pad_len : -1]]\n",
    "        )\n",
    "        \n",
    "        pdf_mat_num = np.exp(-0.5 * ((grid - grid[:, None]) / bw_adj[:, None]) ** 2) * grid_count[:, None]\n",
    "        pdf_mat_den = ((2 * np.pi) ** 0.5 * bw_adj[:, None]) \n",
    "        pdf_mat = pdf_mat_num / pdf_mat_den\n",
    "        pdf = np.sum(pdf_mat[:, grid_len:(2 * grid_len)], axis=0) / len(x)\n",
    "        \n",
    "        return grid[grid_len:(2 * grid_len)], pdf\n",
    "    else:\n",
    "        pdf_mat_num = np.exp(-0.5 * ((grid - grid[:, None]) / bw_adj[:, None]) ** 2) * grid_count[:, None]\n",
    "        pdf_mat_den = ((2 * np.pi) ** 0.5 * bw_adj[:, None]) \n",
    "        pdf_mat = pdf_mat_num / pdf_mat_den\n",
    "        pdf = np.sum(pdf_mat, axis=0) / len(x)\n",
    "        \n",
    "        return grid, pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User accesible function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_density(\n",
    "    x,\n",
    "    bw=\"silverman\",\n",
    "    grid_len=256, \n",
    "    extend=True, \n",
    "    bound_correction=False, \n",
    "    adaptive=False,\n",
    "    extend_fct=0.5, \n",
    "    bw_fct=1,\n",
    "    bw_return=False,\n",
    "    custom_lims=None\n",
    "):\n",
    "    \n",
    "    # Check `x` is from appropiate type\n",
    "    x = _check_type(x)\n",
    "    \n",
    "    # Preliminary calculations\n",
    "    x_len = len(x)\n",
    "    x_min = np.min(x)\n",
    "    x_max = np.max(x)\n",
    "    \n",
    "    # Length warning:\n",
    "    # Not completely sure whether it is necessary\n",
    "    _len_warning(x_len)\n",
    "    \n",
    "    # Set up number of bins\n",
    "    # Should I enable larger grids?\n",
    "    if grid_len > 512:\n",
    "        grid_len = 512\n",
    "    if grid_len < 100:\n",
    "        grid_len = 100\n",
    "    grid_len = int(grid_len)\n",
    "        \n",
    "    # Set up domain\n",
    "    # `custom_limits` overrides `extend`\n",
    "    # `bound_correction` overrides `extend`\n",
    "    if custom_lims is not None:\n",
    "        assert isinstance(custom_lims, (list, tuple))\n",
    "        assert len(custom_lims) == 2\n",
    "        assert custom_lims[0] < custom_lims[1]\n",
    "        grid_min = custom_lims[0]\n",
    "        grid_max = custom_lims[1]\n",
    "    elif extend and not bound_correction:\n",
    "        assert isinstance(extend_fct, (int, float))\n",
    "        grid_extend = extend_fct * np.std(x)\n",
    "        grid_min = x_min - grid_extend\n",
    "        grid_max = x_max + grid_extend\n",
    "    else:\n",
    "        grid_min = x_min\n",
    "        grid_max = x_max\n",
    "        \n",
    "    # Bandwidth estimation\n",
    "    assert isinstance(bw_fct, (int, float))\n",
    "    bw = bw_fct * get_bw(x, bw)\n",
    "    \n",
    "    # Density estimation\n",
    "    if adaptive:\n",
    "        grid, pdf = kde_adaptive(x, bw, grid_len, grid_min, grid_max, bound_correction)\n",
    "    else:\n",
    "        grid, pdf = kde_convolution(x, bw, grid_len, grid_min, grid_max, bound_correction)\n",
    "    \n",
    "    return grid, pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density estimation via Gaussian Mixture and EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_mixture(grid, mu, var, weight):\n",
    "    out = np.sum(list((map(lambda m, v, w: _norm_pdf(grid, m, v, w), mu, var, weight))), axis=0)\n",
    "    return out\n",
    "\n",
    "def _norm_pdf(grid, mu, var, weight):\n",
    "    # 1 / np.sqrt(2 * np.pi) = 0.3989423\n",
    "    out = np.exp(-0.5 * ((grid - mu)) ** 2 / var) * 0.3989423 * (var ** -0.50) * weight\n",
    "    return out   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User accesible function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_density_em(\n",
    "    x, \n",
    "    gauss_n=None, \n",
    "    grid_len=256, \n",
    "    extend=True,\n",
    "    extend_fct=0.5,\n",
    "    custom_lims=None,\n",
    "    iter_max=200, \n",
    "    tol=0.002, \n",
    "    verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Adaptative Gaussian KDE by E-M algorithm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy array\n",
    "        1 dimensional array of sample data from the variable for which a \n",
    "        density estimate is desired.\n",
    "    gauss_n : float, optional\n",
    "        Number of Gaussian kernels to be used in the mixture. \n",
    "        More kernels mean more accuracy but larger computation times. \n",
    "        Based on own experience, upper bound was set to 30.\n",
    "        Defaults to None, which picks the number heuristically.\n",
    "    grid_len : int, optional\n",
    "        Number of points where the kernel is evaluated. \n",
    "        Defaults to 256.\n",
    "    extend: boolean, optional\n",
    "        Whether to extend the domain of the observed data or not. \n",
    "        Defaults to True.\n",
    "    extend_fct: float, optional\n",
    "        The value that multiplies the standard deviation of `x`\n",
    "        that is used o extend the domain.\n",
    "        Defaults to 0.5.\n",
    "    custom_lims: list or tuple, optional\n",
    "        Custom limits for the domain of `x`.\n",
    "        The length of the list/tuple must be 2.\n",
    "        Defaults to None.\n",
    "    iter_max: float, optional\n",
    "        Number of maximum iterations for the E-M algorithm\n",
    "        Defaults to 200.\n",
    "    tol: float, optional\n",
    "        Maximum tolerated difference between steps of the E-M algorithm\n",
    "        Defaults to 0.005 (experimental).\n",
    "    verbose: boolean, optional\n",
    "        Indicates whether to print information related to each E-M step.\n",
    "        Defaults to False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    grid : Gridded numpy array for the x values.\n",
    "    pdf : Numpy array for the density estimates.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check `x` is from appropiate type\n",
    "    x = _check_type(x)\n",
    "    \n",
    "    # Preliminary calculations\n",
    "    x_len = len(x)\n",
    "    x_min = np.min(x)\n",
    "    x_max = np.max(x)\n",
    "    x_std = np.std(x)\n",
    "    \n",
    "    # Length warning:\n",
    "    # Not completely sure whether it is necessary\n",
    "    _len_warning(x_len)\n",
    "    \n",
    "    # Set up number of bins\n",
    "    # Should I enable larger grids?\n",
    "    if grid_len > 512:\n",
    "        grid_len = 512\n",
    "    if grid_len < 100:\n",
    "        grid_len = 100\n",
    "    grid_len = int(grid_len)\n",
    "    \n",
    "    # Set up domain\n",
    "    # `custom_limits` overrides `extend`\n",
    "    if custom_lims is not None:\n",
    "        assert isinstance(custom_lims, (list, tuple))\n",
    "        assert len(custom_lims) == 2\n",
    "        assert custom_lims[0] < custom_lims[1]\n",
    "        grid_min = custom_lims[0]\n",
    "        grid_max = custom_lims[1]\n",
    "    elif extend:\n",
    "        grid_extend = extend_fct * x_std\n",
    "        grid_min = x_min - grid_extend\n",
    "        grid_max = x_max + grid_extend\n",
    "    else:\n",
    "        grid_min = x_min\n",
    "        grid_max = x_max\n",
    "    \n",
    "    grid = np.linspace(grid_min, grid_max, num=grid_len)\n",
    "    \n",
    "    # Set up number of (Gaussian) kernels - heuristic\n",
    "    if gauss_n is None:\n",
    "        gauss_n = int(np.ceil(x_len ** 0.20)) + 10\n",
    "    \n",
    "    if gauss_n > 30:\n",
    "        gauss_n = 30\n",
    "    gauss_n = int(gauss_n)\n",
    "    \n",
    "    # Set up initial values for EM\n",
    "    gauss_w = np.full((gauss_n), 1 / gauss_n)\n",
    "    mean = x[np.linspace(0, x_len - 1, gauss_n, dtype=\"int32\")]\n",
    "    variance = np.full((gauss_n), (x_std ** 2) / (gauss_n * 0.5)) # heuristic\n",
    "    \n",
    "    llh_matrix = np.zeros((x_len, gauss_n))\n",
    "    llh_current = float('-inf')\n",
    "    \n",
    "    for iter in range(0, iter_max):\n",
    "\n",
    "        llh_prev = llh_current\n",
    "        \n",
    "    # Expectation step \n",
    "        z_sq = ((x - mean[:, None]) ** 2) / variance[:, None]\n",
    "        llh_matrix = -0.5 * (np.log(2 * np.pi) + z_sq) - np.log(np.sqrt(variance[:, None])) + np.log(gauss_w[:, None])\n",
    "        llh_matrix = np.transpose(llh_matrix)\n",
    "\n",
    "        # Log-sum-exp trick\n",
    "        llh_max = np.amax(llh_matrix, axis=1)\n",
    "        joint_probs = np.exp(llh_matrix - llh_max[:, None])\n",
    "        pdf = np.sum(joint_probs, axis=1)\n",
    "        logpdf = np.log(pdf) + llh_max\n",
    "        llh_current = np.sum(logpdf)\n",
    "        resp = joint_probs / pdf[:, None]\n",
    "        \n",
    "    # Maximization step\n",
    "        # Estimate means and variances\n",
    "        gauss_w = np.sum(resp, 0)\n",
    "        mean = np.dot(x, resp) / gauss_w            \n",
    "        variance = np.diag(np.dot((x - mean[:, None]) ** 2, resp) / gauss_w)\n",
    "       \n",
    "        # Estimate new weights\n",
    "        gauss_w /= x_len\n",
    "        \n",
    "    # End of EM  \n",
    "        if verbose:\n",
    "            print(\"Step number: \" + str(iter))\n",
    "            print(\"Mean values:      \" + str(mean))\n",
    "            print(\"Variance values:  \" + str(variance))\n",
    "            print(\"Gaussian weights: \" + str(gauss_w))\n",
    "            print(\"---------------------------------------\")\n",
    " \n",
    "        if np.abs((llh_current - llh_prev) / llh_current) < tol:\n",
    "            break\n",
    "\n",
    "    # Evaluate grid points in the estimated pdf\n",
    "    pdf = _get_mixture(grid, mean, variance, gauss_w)\n",
    "        \n",
    "    return grid, pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
